{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torchvision.transforms import transforms\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.nn import CrossEntropyLoss\n",
    "\n",
    "from train import Trainer\n",
    "from model import FastSCNN\n",
    "from dataset import PostdamDataset\n",
    "from metrics import pixel_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = 100\n",
    "batch_size = 1\n",
    "learning_rate = 0.001\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "ClassesColors = {\n",
    "    (255, 255, 255): 0, # impervious_surfaces\n",
    "    (0, 0, 255): 1, # building\n",
    "    (0, 255, 255): 2, # low_vegetation\n",
    "    (0, 255, 0): 3, # tree\n",
    "    (255, 255, 0): 4, # car\n",
    "    (255, 0, 0): 5 # background\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_class_labels(segmented_image):\n",
    "    w, h = segmented_image.size\n",
    "    ret = torch.zeros(h, w)\n",
    "    for i in range(w):\n",
    "        for j in range(h):\n",
    "            color = segmented_image.getpixel((i, j))\n",
    "            try:\n",
    "                ret[j, i] = ClassesColors[color]\n",
    "            except KeyError:\n",
    "                print(\"Error when converting lable image to class label {color} not im color mapping\")\n",
    "                ret[j, i] = 5\n",
    "    return ret\n",
    "\n",
    "def preprocessing(image, mask):\n",
    "    mask_transformer = transforms.Compose([\n",
    "        transforms.Lambda(lambda x: to_class_labels(x))\n",
    "    ])\n",
    "    image_transformer = transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.3396, 0.3628, 0.3362], [0.1315, 0.1287, 0.1333])\n",
    "    ])\n",
    "    return image_transformer(image).float(), mask_transformer(mask).float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_image_path = './data/2_Ortho_RGB_train/'\n",
    "train_label_path = './data/labels_train/'\n",
    "test_image_path = './data/2_Ortho_RGB_test/'\n",
    "test_label_path = './data/labels_test/'\n",
    "\n",
    "ds_train = PostdamDataset(train_image_path, train_label_path, transform=preprocessing)\n",
    "ds_test = PostdamDataset(test_image_path, test_label_path, transform=preprocessing)\n",
    "dl_train = DataLoader(ds_train, batch_size, shuffle=True)\n",
    "dl_test = DataLoader(ds_test, batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = FastSCNN()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "criterion = CrossEntropyLoss()\n",
    "success_metric = pixel_accuracy\n",
    "trainer = Trainer(model, criterion, optimizer, success_metric, device, None)\n",
    "fit_res = trainer.fit(dl_train,\n",
    "                      dl_test,\n",
    "                      num_epochs= num_epochs,\n",
    "                      checkpoints='src/saved_models/' + model.__class__.__name__)\n",
    "\n",
    "print(fit_res)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
